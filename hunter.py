# filename: hunter.py

import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
import pandas as pd
import numpy as np

# Ù…Ù‚Ø§Ù…ÛŒ Ø§Ù…Ù¾ÙˆØ±Ù¹Ø³
import database_crud as crud
from utils import fetch_twelve_data_ohlc
from fusion_engine import generate_final_signal
from messenger import send_telegram_alert, send_signal_update_alert
from models import SessionLocal
from websocket_manager import manager
from config import STRATEGY

logger = logging.getLogger(__name__)

FINAL_CONFIDENCE_THRESHOLD = STRATEGY["FINAL_CONFIDENCE_THRESHOLD"]
MOMENTUM_FILE = "market_momentum.json"
ANALYSIS_CANDIDATE_COUNT = 4

# ==============================================================================
# â˜…â˜…â˜… Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù† Ú©Ø§ Ú©Ø§Ù… (ÛØ± 5 Ù…Ù†Ù¹ Ø¨Ø¹Ø¯) â˜…â˜…â˜…
# ==============================================================================
async def hunt_for_signals_job():
    """
    ÛŒÛ Ø¬Ø§Ø¨ ÛØ± 5 Ù…Ù†Ù¹ Ú†Ù„ØªÛŒ ÛÛ’ØŒ Ù…Ø§Ø±Ú©ÛŒÙ¹ Ú©Û’ ÚˆÛŒÙ¹Ø§ Ú©Ø§ ØªØ¬Ø²ÛŒÛ Ú©Ø±ØªÛŒ ÛÛ’ Ø§ÙˆØ± Ù†Ø¦Û’ Ø³Ú¯Ù†Ù„ ØªÙ„Ø§Ø´ Ú©Ø±ØªÛŒ ÛÛ’Û”
    """
    logger.info("ğŸ¹ Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù†: Ù†Ø¦Û’ Ù…ÙˆØ§Ù‚Ø¹ Ú©ÛŒ ØªÙ„Ø§Ø´ Ø´Ø±ÙˆØ¹...")
    try:
        with open(MOMENTUM_FILE, 'r') as f:
            market_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        logger.warning("ğŸ¹ Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù†: ØªØ¬Ø²ÛŒÛ Ú©Û’ Ù„ÛŒÛ’ Ú©ÙˆØ¦ÛŒ ÚˆÛŒÙ¹Ø§ ÙØ§Ø¦Ù„ Ù†ÛÛŒÚº Ù…Ù„ÛŒÛ”")
        return

    # Ù¾Ú†Ú¾Ù„Û’ 5 Ù…Ù†Ù¹ Ú©Û’ ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± Ø¨ÛØªØ±ÛŒÙ† Ø§Ù…ÛŒØ¯ÙˆØ§Ø±ÙˆÚº Ú©Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±ÛŒÚº
    five_minutes_ago = datetime.utcnow() - timedelta(minutes=5)
    candidate_scores = {}
    for symbol, history in market_data.items():
        # ØµØ±Ù ÙˆÛ Ø§ÛŒÙ†Ù¹Ø±ÛŒØ² Ù„ÛŒÚº Ø¬Ùˆ Ù¾Ú†Ú¾Ù„Û’ 5 Ù…Ù†Ù¹ Ù…ÛŒÚº Ø¢Ø¦ÛŒ ÛÛŒÚº
        recent_history = [h for h in history if datetime.fromisoformat(h['time']) > five_minutes_ago]
        if len(recent_history) < 2: continue # Ú©Ù… Ø§Ø² Ú©Ù… 2 ÚˆÛŒÙ¹Ø§ Ù¾ÙˆØ§Ø¦Ù†Ù¹Ø³ ÛÙˆÙ†Û’ Ú†Ø§ÛØ¦ÛŒÚº

        df = pd.DataFrame(recent_history)
        total_change = df['change'].sum()
        # Ù…Ø³ØªÙ‚Ù„ Ù…Ø²Ø§Ø¬ÛŒ Ú©Ø§ Ø§Ø³Ú©ÙˆØ± (ØªÙ…Ø§Ù… Ø­Ø±Ú©ØªÛŒÚº Ø§ÛŒÚ© ÛÛŒ Ø³Ù…Øª Ù…ÛŒÚº ÛÛŒÚº ÛŒØ§ Ù†ÛÛŒÚº)
        consistency = abs(df['change'].apply(np.sign).mean())
        
        # Ø§Ø³Ú©ÙˆØ± Ú©Ø§ ÙØ§Ø±Ù…ÙˆÙ„Ø§: Ú©Ù„ ØªØ¨Ø¯ÛŒÙ„ÛŒ * Ù…Ø³ØªÙ‚Ù„ Ù…Ø²Ø§Ø¬ÛŒ Ú©Ø§ Ù…Ø±Ø¨Ø¹
        score = abs(total_change) * (consistency ** 2)
        candidate_scores[symbol] = score

    if not candidate_scores:
        logger.info("ğŸ¹ Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù†: Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø¬ÙˆÚ‘Ø§ Ù…Ø³ØªØ­Ú©Ù… Ø­Ø±Ú©Øª Ú©Û’ Ù…Ø¹ÛŒØ§Ø± Ù¾Ø± Ù¾ÙˆØ±Ø§ Ù†ÛÛŒÚº Ø§ØªØ±Ø§Û”")
        return

    # Ø§Ù…ÛŒØ¯ÙˆØ§Ø±ÙˆÚº Ú©Ùˆ Ø§Ø³Ú©ÙˆØ± Ú©Û’ Ù„Ø­Ø§Ø¸ Ø³Û’ ØªØ±ØªÛŒØ¨ Ø¯ÛŒÚº
    sorted_candidates = sorted(candidate_scores.items(), key=lambda item: item[1], reverse=True)
    pairs_to_analyze = [item[0] for item in sorted_candidates[:ANALYSIS_CANDIDATE_COUNT]]
    
    logger.info(f"ğŸ¹ Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù†: Ú¯ÛØ±Û’ ØªØ¬Ø²ÛŒÛ’ Ú©Û’ Ù„ÛŒÛ’ {len(pairs_to_analyze)} Ø¨ÛØªØ±ÛŒÙ† Ø§Ù…ÛŒØ¯ÙˆØ§Ø± Ù…Ù†ØªØ®Ø¨ Ú©ÛŒÛ’ Ú¯Ø¦Û’: {pairs_to_analyze}")

    db = SessionLocal()
    try:
        active_signals = {s.symbol for s in crud.get_all_active_signals_from_db(db)}
        final_list = [p for p in pairs_to_analyze if p not in active_signals]
        
        if final_list:
            # Ø§ÛŒÚ© ÙˆÙ‚Øª Ù…ÛŒÚº Ø§ÛŒÚ© Ø¬ÙˆÚ‘Û’ Ú©Ø§ ØªØ¬Ø²ÛŒÛ Ú©Ø±ÛŒÚº ØªØ§Ú©Û API Ù¾Ø± Ø¨ÙˆØ¬Ú¾ Ù†Û Ù¾Ú‘Û’
            for pair in final_list:
                await analyze_single_pair(db, pair)
                await asyncio.sleep(2) # ÛØ± ØªØ¬Ø²ÛŒÛ’ Ú©Û’ Ø¨Ø¹Ø¯ 2 Ø³ÛŒÚ©Ù†Úˆ Ú©Ø§ ÙˆÙ‚ÙÛ
    finally:
        if db.is_active:
            db.close()
        logger.info("ğŸ¹ Ø´Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ù†: ØªÙ„Ø§Ø´ Ú©Ø§ Ø¯ÙˆØ± Ù…Ú©Ù…Ù„ ÛÙˆØ§Û”")

async def analyze_single_pair(db: Session, pair: str):
    """Ø§ÛŒÚ© Ø¬ÙˆÚ‘Û’ Ú©Ø§ Ú¯ÛØ±Ø§ ØªØ¬Ø²ÛŒÛ Ú©Ø±ØªØ§ ÛÛ’ Ø§ÙˆØ± Ø³Ú¯Ù†Ù„ Ø¨Ù†Ø§ØªØ§ ÛÛ’Û”"""
    logger.info(f"ğŸ”¬ [{pair}] Ú©Ø§ Ú¯ÛØ±Ø§ ØªØ¬Ø²ÛŒÛ Ú©ÛŒØ§ Ø¬Ø§ Ø±ÛØ§ ÛÛ’...")
    candles = await fetch_twelve_data_ohlc(pair)
    if not candles or len(candles) < 34:
        logger.info(f"ğŸ“Š [{pair}] ØªØ¬Ø²ÛŒÛ Ø±ÙˆÚ©Ø§ Ú¯ÛŒØ§: Ù†Ø§Ú©Ø§ÙÛŒ Ú©ÛŒÙ†ÚˆÙ„ ÚˆÛŒÙ¹Ø§Û”")
        return

    analysis_result = await generate_final_signal(db, pair, candles)
    
    if analysis_result and analysis_result.get("status") == "ok":
        confidence = analysis_result.get('confidence', 0)
        log_message = (f"ğŸ“Š [{pair}] ØªØ¬Ø²ÛŒÛ Ù…Ú©Ù…Ù„: Ø³Ú¯Ù†Ù„ = {analysis_result.get('signal', 'N/A').upper()}, "
                       f"Ø§Ø¹ØªÙ…Ø§Ø¯ = {confidence:.2f}%")
        logger.info(log_message)
        
        if confidence >= FINAL_CONFIDENCE_THRESHOLD:
            update_result = crud.add_or_update_active_signal(db, analysis_result)
            if update_result:
                signal_obj = update_result.signal.as_dict()
                task_type = "new_signal" if update_result.is_new else "signal_updated"
                alert_task = send_telegram_alert if update_result.is_new else send_signal_update_alert
                logger.info(f"ğŸ¯ â˜…â˜…â˜… Ø³Ú¯Ù†Ù„ Ù¾Ø±ÙˆØ³ÛŒØ³ ÛÙˆØ§: {signal_obj['symbol']} ({task_type}) â˜…â˜…â˜…")
                asyncio.create_task(alert_task(signal_obj))
                asyncio.create_task(manager.broadcast({"type": task_type, "data": signal_obj}))
        else:
            logger.info(f"ğŸ“‰ [{pair}] Ø³Ú¯Ù†Ù„ Ù…Ø³ØªØ±Ø¯: Ø§Ø¹ØªÙ…Ø§Ø¯ ({confidence:.2f}%) ØªÚ¾Ø±ÛŒØ´ÙˆÙ„Úˆ Ø³Û’ Ú©Ù… ÛÛ’Û”")
            
    elif analysis_result:
        logger.info(f"â„¹ï¸ [{pair}] ØªØ¬Ø²ÛŒÛ Ù…Ú©Ù…Ù„: Ú©ÙˆØ¦ÛŒ Ø³Ú¯Ù†Ù„ Ù†ÛÛŒÚº Ø¨Ù†Ø§Û” ÙˆØ¬Û: {analysis_result.get('reason', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')}")
    
